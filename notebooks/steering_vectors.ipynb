{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c88f4bb",
   "metadata": {},
   "source": [
    "## Steering Vectors: Activation Engineering in GPT-2\n",
    "\n",
    "This notebook implements **Activation Steering**, a technique to control model behavior and prediction by intervening in the residual stream during inference. A good reference I came across for this is [here](https://www.lesswrong.com/posts/ndyngghzFY388Dnew/implementing-activation-steering).\n",
    "\n",
    "**Core Concept:**\n",
    "$$ h_{steered} = h_{original} + \\alpha \\cdot \\vec{v}_{concept} $$\n",
    "\n",
    "1. **Extract** a \"sentiment direction\" using contrastive prompt pairs\n",
    "2. **Visualize** this direction using PCA (building our previous work)\n",
    "3. **Intervene** with Pytorch hooks to steer generation towards positive or negative sentiment\n",
    "4. **Validate** the effect quantitatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab39f723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Running on: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c9520cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the model load stuff\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07302578",
   "metadata": {},
   "source": [
    "## Data Prep (Contrastive Pairs)\n",
    "\n",
    "we need pairs of prompts that differ *only* in the target concept (sentiment).\n",
    "\n",
    "**Critical:** We must ensure both prompts tokenize to the same length so we can subtract their residual streams directly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1fe8075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_pairs():\n",
    "    \"\"\"\n",
    "    Returns list of (positive, negative) prompt tuples.\n",
    "\n",
    "    Ref: https://www.kaggle.com/code/shakka/sentiment-analysis-using-contrastive-learning\n",
    "    \"\"\"\n",
    "\n",
    "    return [\n",
    "        (\"I think this movie is amazing\", \"I think this movie is terrible\"),\n",
    "        (\"The food at this restaurant is delicious\", \"The food at this restaurant is disgusting\"),\n",
    "        (\"I am feeling very happy today\", \"I am feeling very sad today\"),\n",
    "        (\"The product quality is excellent\", \"The product quality is awful\"),\n",
    "        (\"My experience was wonderful\", \"My experience was horrible\"),\n",
    "        (\"He is a very kind person\", \"He is a very mean person\"),\n",
    "        (\"The weather is beautiful\", \"The weather is nasty\"),\n",
    "        (\"This solution is perfect\", \"This solution is useless\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fde86bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = get_sentiment_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa77204c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive                                 | Negative                                 | Match?\n",
      "------------------------------------------------------------------------------------------\n",
      "I think this movie is amazing            | I think this movie is terrible           | True (6 vs 6)\n",
      "The food at this restaurant is delicious | The food at this restaurant is disgusting | True (7 vs 7)\n",
      "I am feeling very happy today            | I am feeling very sad today              | True (6 vs 6)\n",
      "The product quality is excellent         | The product quality is awful             | True (5 vs 5)\n",
      "My experience was wonderful              | My experience was horrible               | True (4 vs 4)\n",
      "He is a very kind person                 | He is a very mean person                 | True (6 vs 6)\n",
      "The weather is beautiful                 | The weather is nasty                     | True (4 vs 4)\n",
      "This solution is perfect                 | This solution is useless                 | True (4 vs 4)\n",
      "\n",
      "Using 8 valid contrastive pairs\n"
     ]
    }
   ],
   "source": [
    "# quick verification on token lengths\n",
    "print(f\"{'Positive':<40} | {'Negative':<40} | {'Match?'}\")\n",
    "print(\"-\"*90)\n",
    "valid_pairs = []\n",
    "for pos, neg in pairs:\n",
    "    tok_pos = tokenizer(pos, return_tensors='pt')['input_ids'][0]\n",
    "    tok_neg = tokenizer(neg, return_tensors='pt')['input_ids'][0]\n",
    "    match = len(tok_pos) == len(tok_neg)\n",
    "    print(f\"{pos:<40} | {neg:<40} | {match} ({len(tok_pos)} vs {len(tok_neg)})\")\n",
    "    if match:\n",
    "        valid_pairs.append((pos, neg))\n",
    "\n",
    "print(f\"\\nUsing {len(valid_pairs)} valid contrastive pairs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
