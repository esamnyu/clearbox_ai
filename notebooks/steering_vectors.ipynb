{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c88f4bb",
   "metadata": {},
   "source": [
    "## Steering Vectors: Activation Engineering in GPT-2\n",
    "\n",
    "This notebook implements **Activation Steering**, a technique to control model behavior and prediction by intervening in the residual stream during inference. A good reference I came across for this is [here](https://www.lesswrong.com/posts/ndyngghzFY388Dnew/implementing-activation-steering).\n",
    "\n",
    "**Core Concept:**\n",
    "$$ h_{steered} = h_{original} + \\alpha \\cdot \\vec{v}_{concept} $$\n",
    "\n",
    "1. **Extract** a \"sentiment direction\" using contrastive prompt pairs\n",
    "2. **Visualize** this direction using PCA (building our previous work)\n",
    "3. **Intervene** with Pytorch hooks to steer generation towards positive or negative sentiment\n",
    "4. **Validate** the effect quantitatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab39f723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Running on: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9520cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the model load stuff\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07302578",
   "metadata": {},
   "source": [
    "## Data Prep (Contrastive Pairs)\n",
    "\n",
    "we need pairs of prompts that differ *only* in the target concept (sentiment).\n",
    "\n",
    "**Critical:** We must ensure both prompts tokenize to the same length so we can subtract their residual streams directly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe8075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_pairs():\n",
    "    \"\"\"\n",
    "    Returns list of (positive, negative) prompt tuples.\n",
    "\n",
    "    Ref: https://www.kaggle.com/code/shakka/sentiment-analysis-using-contrastive-learning\n",
    "    \"\"\"\n",
    "\n",
    "    return [\n",
    "        (\"I think this movie is amazing\", \"I think this movie is terrible\"),\n",
    "        (\"The food at this restaurant is delicious\", \"The food at this restaurant is disgusting\"),\n",
    "        (\"I am feeling very happy today\", \"I am feeling very sad today\"),\n",
    "        (\"The product quality is excellent\", \"The product quality is awful\"),\n",
    "        (\"My experience was wonderful\", \"My experience was horrible\"),\n",
    "        (\"He is a very kind person\", \"He is a very mean person\"),\n",
    "        (\"The weather is beautiful\", \"The weather is nasty\"),\n",
    "        (\"This solution is perfect\", \"This solution is useless\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fde86bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = get_sentiment_pairs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
